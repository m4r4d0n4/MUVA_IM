{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                      Imagen Médica              -                Máster Visión Artificial (2023-2024)\n",
    "\n",
    "*María Cornejo Antonaya (m.cornejo.2023@alumnos.urjc.es)*\n",
    "\n",
    "*Nuria Miralles Gavara (n.miralles.2023@alumnos.urjc.es)*\n",
    "\n",
    "*Juan Montes Cano (juan.montes@urjc.es)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3: Registro de Imágenes Médicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la presente práctica, se alinean dos imágenes para su posterior análisis conjunto. Este procedimiento se ha realizado empleando el software gratuito 3D Slicer, utilizado para la visualización, procesamiento, segmentación, registro y análisis de imágenes médicas. Se aplica en diversos contextos clínicos y biomédicos. \n",
    "Además, como parte de este proceso, se llevará a cabo el desarrollo de un algoritmo en Python3 para realizar un registro rígido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Uso y análisis de algoritmos de registro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Registro intramodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar, se han analizado detenidamente las dos imágenes de resonancia magnética proporcionadas, considerando la imagen *mr1.nii* como el fondo y la *mr2.nii* como  el primer plano. Tras una evaluación inicial del resultado obtenido, se puede confirmar que la alineación de ambas imágenes no es precisa, lo cual se evidencia en un conjunto desalineado. ([Vídeo A1](https://www.youtube.com/watch?v=9ku8WJHLKMU))\n",
    "\n",
    "A continuación, se ha aplicado el filtro Checkboard con el objetivo de comparar los resultados del registro de las imágenes. En este contexto, no se ha obtenido el resultado esperado debido a la falta de alineación entre las imágenes. ([Vídeo A2](https://www.youtube.com/watch?v=2TMEdWt3GrM))\n",
    "\n",
    "Posteriormente, se ha procedido a realizar el registro de las imágenes con el objetivo de alinear la posición y orientación de ambas. La plataforma Slider 3D ofrece el módulo “General Registration (BRAINS)”, el cual se recomienda para resonancias magnéticas cerebrales. Este módulo se ha configurado utilizando la imagen *mr1.nii* como imagen fija y la imagen a mover *mr2.nii*. Ambas imágenes, en formato de escala de grises, han sido alineadas automáticamente mediante métodos de registro basados en la intensidad de las mismas. ([Vídeo A3](https://www.youtube.com/watch?v=rjNm-aDPXH0))\n",
    "\n",
    "Después, se han examinado cada una de las opciones facilitadas en la sección de “Registration Phase”. En los dos primeros escenarios (7 y 10 grados de libertad), donde se implementa una combinación de  transformación rígida (rotación y traslación) y escalado en ambos casos y sesgo en el caso de 10 grados de libertad; se observa una tendencia hacia formas más alargadas. Por otro lado, al aumentar el grado de libertad con respecto a las demás opciones, tanto la transformación afín como la transformación BSpline conducen a formas más realistas, dado que ambas permiten una deformación más natural de la imagen, resultando más realista y próxima a la anatomía observada. ([Vídeo A4](https://www.youtube.com/watch?v=-r-m7dDzdA0))\n",
    "\n",
    "En el caso de las transformaciones afines se conservan las propiedades geométricas básicas, como la proporcionalidad, lo que hace una deformación más suave y natural.\n",
    "Para la transformación BSpline, al ser un método no rígido, se emplea para modelar deformaciones de mayor complejidad. ([Vídeo A6](https://www.youtube.com/watch?v=nW0gweEOpc8))\n",
    "\n",
    "Cada uno de los escenarios planteados, se ha grabado en vídeos disponibles en los enlaces anteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Registro multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este segundo apartado, se visualizan la imagen de resonancia magnética, denominada mr1.nii, y la imagen de tomografía computarizada, *ct.nii*. El resultado obtenido muestra la imagen, *ct.nii*, considerablemente desplazada en comparación con la imagen *mr1.nii*, la cual se ha considerado como fondo. Esta disparidad se debe a que ambas imágenes son de distinta modalidad, así como los equipos utilizados por su adquisición. Además, es importante considerar la posición y estado del paciente dado que influyen en las discrepancias observadas. \n",
    "El resultado obtenido se muestra en [Vídeo B1](https://www.youtube.com/watch?v=n7QXEnDdCnk).\n",
    "\n",
    "A continuación, se han analizado ambas imágenes utilizando el filtro Checkerboard, observando un resultado deficiente, debido a las conclusiones obtenidas en la sección anterior y a la falta de alineación entre las imágenes. En este caso, la imagen aparece segmentada en 4 regiones, las cuales no guardan correspondencia entre sí. ([Vídeo B2](https://www.youtube.com/watch?v=c8CIDEKctes))\n",
    "\n",
    "Después, se han registrado ambas imágenes mediante un registro rígido, obteniendo un resultado insatisfactorio debido a que las imágenes se encuentran descuadradas. La imagen resultante aparece desplazada en la parte superior izquierda, lo que impide la visualización precisa y la identificación de la cabeza. \n",
    "\n",
    "Para abordar el problema del alineamiento, se ha empleado la información relativa de los centroides de ambos cráneos, para ello se ha utilizado la opción de  “Transform Initilization Settings”. El resultado obtenido es una imagen centrada; para una comprensión más detallada, se sugiere visualizar [Vídeo B4](https://www.youtube.com/watch?v=dbUk16UgpyA). \n",
    "\n",
    "Por último, se aborda un proceso de registro elástico de ambas imágenes utilizando la transformación Spline e incorporando la optimización del registro con los centroides. Mediante este procedimiento, se ha fijado la imagen de resonancia magnética y se ha ido moviendo la imagen de tomografía computarizada, y viceversa, obteniendo resultados satisfactorios en ambos casos. \n",
    "\n",
    "Además, se ha incorporado la librería de código abierto Elastix para llevar a cabo el registro de las imágenes. Durante este proceso, se han analizado diversas opciones disponibles de esta herramienta. Se observa que al implementar la opción de preset genérico, se obtuvieron resultados distorsionados y desalineados especialmente en la región nasal. En cambio, cuando se utiliza preset “3dmrt1 monomodal brain”, se logra una representación precisa del cráneo. Este resultado se debe a la capacidad de preset de utilizar una plantilla de un modelo anatómico del cráneo , permitiendo conservar las regiones del cráneo y mejorando la calidad del registro. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementación de un algoritmo de registro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se ha implementado un algoritmo de registro rígido en Python, que se centra en trasladar y rotar imágenes sin deformarlas. La función *aplicar_transformacion_rigida()* permite rotar y trasladar una imagen según un ángulo de rotación y desplazamientos en x e y. Esto se logra calculando una matriz de transformación que rota la imagen alrededor de su centro y luego aplica los desplazamientos necesarios.\n",
    "\n",
    "El siguiente paso implica calcular la interpolación trilineal entre dos imágenes, esencial para obtener valores intermedios entre los píxeles de ambas. Esta interpolación asegura una alineación precisa al considerar la contribución de cada imagen de acuerdo a los pesos dados.\n",
    "\n",
    "Además, se calcula la métrica de información mutua entre las imágenes, que es una medida de la dependencia estadística entre ellas. Esto se hace normalizando los valores de píxeles a un rango común y luego calculando la información mutua utilizando la *función mutual_info_score()* de *sklearn.metrics*. Este valor proporciona una medida de la similitud entre las imágenes y es útil para evaluar la calidad del registro.\n",
    "\n",
    "Al experimentar con las transformaciones, se ha observado que la métrica de información mutua se comporta de manera esperada. Se ha notado que a medida que las transformaciones son más grandes, la información mutua disminuye. Esto se debe a que la información mutua disminuye cuando hay más incertidumbre, es decir, cuando las imágenes son más diferentes.\n",
    "\n",
    "Finalmente, se realiza la optimización de los parámetros de la transformación para minimizar la diferencia entre la imagen fija y la imagen móvil. Se definen tres funciones de costo separadas para la rotación, la traslación en el eje x y la traslación en el eje y. Cada función de costo toma como entrada el conjunto de parámetros a optimizar y calcula la diferencia entre las dos imágenes. Utilizando la función *minimize* de *SciPy*, se busca el conjunto óptimo de parámetros que minimice esta diferencia. Es importante mencionar que en casos de grandes discrepancias entre las imágenes, la optimización puede no converger adecuadamente hacia el mínimo global.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Interpolación\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "def trilinear_interpolation(image1, image2, weights):\n",
    "    # Verificar que las imágenes tengan las mismas dimensiones\n",
    "    assert image1.shape == image2.shape, \"Las imágenes deben tener las mismas dimensiones\"\n",
    "\n",
    "    # Crear la función interpoladora para la primera imagen\n",
    "    interpolator_image1 = RegularGridInterpolator((np.arange(image1.shape[0]), np.arange(image1.shape[1])), image1)\n",
    "    \n",
    "    # Crear la función interpoladora para la segunda imagen\n",
    "    interpolator_image2 = RegularGridInterpolator((np.arange(image2.shape[0]), np.arange(image2.shape[1])), image2)\n",
    "\n",
    "    # Calcular la interpolación trilineal para cada punto en el espacio bidimensional\n",
    "    interpolated_values = np.zeros_like(image1)\n",
    "    for i in range(image1.shape[0]):\n",
    "        for j in range(image1.shape[1]):\n",
    "            position = np.array([i, j])\n",
    "            value1 = interpolator_image1(position)\n",
    "            value2 = interpolator_image2(position)\n",
    "            interpolated_values[i, j] = value1 * (1 - weights) + value2 * weights\n",
    "    \n",
    "    return interpolated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Información mutua\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def calcular_mutual_info(image1, image2):\n",
    "    # Asegurarse de que las imágenes tengan el mismo tamaño\n",
    "    assert image1.shape == image2.shape, \"Las imágenes deben tener el mismo tamaño\"\n",
    "\n",
    "    # Normalizar los valores de píxeles a [0, 255]\n",
    "    image1_norm = (image1 - image1.min()) / (image1.max() - image1.min()) * 255\n",
    "    image2_norm = (image2 - image2.min()) / (image2.max() - image2.min()) * 255\n",
    "\n",
    "    # Convertir los valores de píxeles a enteros\n",
    "    image1_norm = image1_norm.astype(np.uint8)\n",
    "    image2_norm = image2_norm.astype(np.uint8)\n",
    "\n",
    "    # Calcular la métrica de información mutua\n",
    "    mi = mutual_info_score(image1_norm.ravel(), image2_norm.ravel())\n",
    "\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transformación rígida\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def nifti_to_opencv(image_path, index):\n",
    "    # Cargar la imagen desde el archivo NIfTI\n",
    "    imagen_nifti = nib.load(image_path)\n",
    "    \n",
    "    # Obtener los datos de la imagen\n",
    "    imagen = imagen_nifti.get_fdata()[:, :, index]\n",
    "    \n",
    "    # Normalizar los valores de píxeles entre 0 y 255 (opcional)\n",
    "    imagen = (imagen - imagen.min()) / (imagen.max() - imagen.min()) * 255\n",
    "    \n",
    "    # Convertir la imagen a formato compatible con OpenCV (uint8)\n",
    "    imagen_opencv = cv2.convertScaleAbs(imagen)\n",
    "    \n",
    "    return imagen_opencv\n",
    "\n",
    "def aplicar_transformacion_rigida(imagen, angulo_rotacion, traslacion_x, traslacion_y):\n",
    "    # Obtenemos las dimensiones de la imagen\n",
    "    alto, ancho = imagen.shape[:2]\n",
    "    \n",
    "    # Calculamos el punto central de la imagen\n",
    "    centro = (ancho // 2, alto // 2)\n",
    "    \n",
    "    # Definimos la matriz de transformación\n",
    "    matriz_transformacion = cv2.getRotationMatrix2D(centro, angulo_rotacion, 1)\n",
    "    \n",
    "    # Aplicamos la traslación\n",
    "    matriz_transformacion[0, 2] += traslacion_x\n",
    "    matriz_transformacion[1, 2] += traslacion_y\n",
    "    \n",
    "    # Aplicamos la transformación a la imagen\n",
    "    imagen_transformada = cv2.warpAffine(imagen, matriz_transformacion, (ancho, alto))\n",
    "    \n",
    "    return imagen_transformada\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar la imagen\n",
    "    index = 93\n",
    "    imagen = nifti_to_opencv(\"images/mr1.nii\",index)\n",
    "    #plt.imshow(imagen, cmap='gray')\n",
    "    # Parámetros de la transformación\n",
    "    angulo_rotacion = 4\n",
    "    traslacion_x = 2\n",
    "    traslacion_y = 5\n",
    "    \n",
    "    # Aplicar la transformación\n",
    "    imagen_transformada = aplicar_transformacion_rigida(imagen, angulo_rotacion, traslacion_x, traslacion_y)\n",
    "    \n",
    "    imagen_interpolada = trilinear_interpolation(imagen,imagen_transformada,0.1)\n",
    "\n",
    "    mutual_info = calcular_mutual_info(imagen, imagen_interpolada)\n",
    "\n",
    "    print(\"Métrica de Información Mutua entre imagen original e imagen interpolada:\", mutual_info)\n",
    "    # Mostrar la imagen original y la transformada\n",
    "    cv2.imshow(\"Imagen Original\", imagen)\n",
    "    cv2.imshow(\"Imagen Transformada\", imagen_transformada)\n",
    "    cv2.imshow(\"Imagen Interpolada\", imagen_interpolada)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Optimización\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from rigid import aplicar_transformacion_rigida,nifti_to_opencv\n",
    "\n",
    "def f_rot(x,img,img_edit):\n",
    "        img_edit = aplicar_transformacion_rigida(img_edit,x[0],0,0)\n",
    "        diff = np.abs(img - img_edit)\n",
    "        return np.sum(diff)\n",
    "        # Por ejemplo, una función de prueba como la parábola en tres dimensiones\n",
    "\n",
    "imagen_objetivo = nifti_to_opencv(\"images/mr1.nii\",93)\n",
    "imagen = aplicar_transformacion_rigida(nifti_to_opencv(\"images/mr1.nii\",93),10,0,0)\n",
    "x = np.array([0]) #[0] es rotacion [1] traslacion x [2] traslacion y\n",
    "\n",
    "d = minimize(fun = f_rot,x0= x,args=(imagen_objetivo,imagen),method=\"Powell\")\n",
    "print(\"ROTACION :\" + str(d.x))\n",
    "\n",
    "def f_tras_x(x,img,img_edit):\n",
    "        img_edit = aplicar_transformacion_rigida(img_edit,0,x[0],0)\n",
    "        diff = np.abs(img - img_edit)\n",
    "        return np.sum(diff)\n",
    "        # Por ejemplo, una función de prueba como la parábola en tres dimensiones\n",
    "\n",
    "imagen_objetivo = nifti_to_opencv(\"images/mr1.nii\",93)\n",
    "imagen = aplicar_transformacion_rigida(nifti_to_opencv(\"images/mr1.nii\",93),0,10,0)\n",
    "x = np.array([0]) #[0] es rotacion [1] traslacion x [2] traslacion y\n",
    "\n",
    "d = minimize(fun = f_tras_x,x0= x,args=(imagen_objetivo,imagen),method=\"Powell\")\n",
    "print(\"TRASLACION X :\" + str(d.x))\n",
    "\n",
    "\n",
    "def f_tras_y(x,img,img_edit):\n",
    "        img_edit = aplicar_transformacion_rigida(img_edit,0,0,x[0])\n",
    "        diff = np.abs(img - img_edit)\n",
    "        return np.sum(diff)\n",
    "        # Por ejemplo, una función de prueba como la parábola en tres dimensiones\n",
    "\n",
    "imagen_objetivo = nifti_to_opencv(\"images/mr1.nii\",93)\n",
    "imagen = aplicar_transformacion_rigida(nifti_to_opencv(\"images/mr1.nii\",93),0,0,5)\n",
    "x = np.array([0]) #[0] es rotacion [1] traslacion x [2] traslacion y\n",
    "\n",
    "d = minimize(fun = f_tras_y,x0= x,args=(imagen_objetivo,imagen),method=\"Powell\")\n",
    "print(\"TRASLACION Y :\" + str(d.x))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
