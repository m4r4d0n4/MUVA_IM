{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                      Imagen Médica              -                Máster Visión Artificial (2023-2024)\n",
    "\n",
    "**María Cornejo Antonaya (m.cornejo.2023@alumnos.urjc.es)**\n",
    "\n",
    "**Nuria Miralles Gavara (n.miralles.2023@alumnos.urjc.es)**\n",
    "\n",
    "**Juan Montes Cano (juan.montes@urjc.es)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica 2: Segmentación de imagen\n",
    "\n",
    "En la presente práctica, se analizan e implementan diversos algoritmos de segmentación de imagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio A) Crecimiento de regiones\n",
    "\n",
    "El método de crecimiento de regiones se basa en la selección de una semilla en la imagen y la definición de un rango de nivel de gris que caracteriza a la región de interés. A partir de esta semilla y el rango especificado, se procede a expandir iterativamente la región, agregando píxeles adyacentes que cumplen con el criterio de pertenecer al rango de nivel de gris establecido. Este proceso se detiene cuando ya no se pueden agregar más píxeles que cumplan con las condiciones definidas.\n",
    "\n",
    "En el script el usuario podrá elegir donde se inicializa la semilla, y podrá ver como es incremental la segmentación descomentando las líneas 46 y 47 del script `ejer1.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(f'Coordenada: ({x}, {y})')\n",
    "\n",
    "\n",
    "def region_grow(image, seed_coords, threshold_min, threshold_max):\n",
    "    # Create an empty mask to store the region\n",
    "    mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    \n",
    "    # Create a set to store the coordinates of pixels that have been processed\n",
    "    processed_pixels = set()\n",
    "    \n",
    "    # Get the seed pixel value\n",
    "    seed_value = image[seed_coords[1], seed_coords[0]]\n",
    "    \n",
    "    # Create a queue to store the coordinates of pixels to be processed\n",
    "    queue = []\n",
    "    queue.append(seed_coords)\n",
    "    \n",
    "    # Process the queue until it's empty\n",
    "    while queue:\n",
    "        # Get the next pixel coordinates from the queue\n",
    "        x, y = queue.pop(0)\n",
    "        \n",
    "        # Check if the pixel is within the image boundaries and has not been processed before\n",
    "        if x >= 0 and x < image.shape[1] and y >= 0 and y < image.shape[0] and (x, y) not in processed_pixels:\n",
    "            # Mark the pixel as processed\n",
    "            processed_pixels.add((x, y))\n",
    "            # Check if the pixel value is within the threshold\n",
    "            if threshold_min <= image[y, x][0] <= threshold_max:\n",
    "                \n",
    "                # Set the pixel value in the mask\n",
    "                mask[y, x] = 255\n",
    "                \n",
    "                # Add the neighboring pixels to the queue\n",
    "                queue.append((x - 1, y))\n",
    "                queue.append((x + 1, y))\n",
    "                queue.append((x, y - 1))\n",
    "                queue.append((x, y + 1))\n",
    "        #cv2.imshow(\"Mask\", mask)\n",
    "        #cv2.waitKey(1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Path to the image file\n",
    "image_path = \"MaterialP2/hueso.tif\"\n",
    "\n",
    "# Read the image using OpenCV\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is not None:\n",
    "    # Display the image\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    # Establecer la función de devolución de llamada para el evento de clic del mouse\n",
    "    cv2.setMouseCallback('Image', click_event)\n",
    "    # Wait for a key press\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    '''\n",
    "    seed_x = int(input(\"Enter the x coordinate of the seed pixel: \"))\n",
    "    seed_y = int(input(\"Enter the y coordinate of the seed pixel: \"))'''\n",
    "\n",
    "    seed_x = 153\n",
    "    seed_y = 281\n",
    "    print(seed_x, seed_y)\n",
    "\n",
    "    # Get the threshold from the user\n",
    "    '''\n",
    "    threshold_max = int(input(\"Enter the threshold value max: \"))\n",
    "    threshold_min = int(input(\"Enter the threshold value min: \"))\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    threshold_max = 180 # 220 te detecta mas hueso\n",
    "    threshold_min = 110\n",
    "    \n",
    "    # Perform region growing\n",
    "    mask = region_grow(image, (seed_x, seed_y), threshold_min, threshold_max)\n",
    "    \n",
    "    # Display the mask\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    \n",
    "    # Wait for a key press\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    # Close all windows\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Failed to load the image.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Se muestra como la zona ha ido creciendo para realizar la segmentación:\n",
    "\n",
    "\n",
    "<img src=\"A1.jpg\" alt=\"Descripción de la imagen\" width=\"700\"/>\n",
    "\n",
    "\n",
    "<img src=\"A2.jpg\" alt=\"Descripción de la imagen\" width=\"700\"/>\n",
    "\n",
    "\n",
    "<img src=\"A3.jpg\" alt=\"Descripción de la imagen\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio B) Segmentación usando algoritmo EM\n",
    "\n",
    "En este apartado se utiliza el algoritmo EM para la segmentación. Considerando el histograma de una imagen formado por gaussianas de cada clase de la imagen, se lleva a cabo la segmentación buscando las gaussianas que definan mejor el histograma. Este algoritmo maximiza la verosimilitud y permite incluir información a priori.\n",
    "\n",
    "Para desarollar este apartado se ha utilizado la imagen del corte axial de un cerebro facilitado, brain.bmp. Inicialmente, se ha segmentado la imagen con 4 y 6 clases. Obteniendo un resultado nulo con 4 clases y mejorandolo con 6 clases obteniendo una segmentación más precisa.\n",
    "\n",
    "TO-DO LOS APARTADITOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "codigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio C) Segmentación usando el algoritmo Watershed\n",
    "\n",
    "El algoritmo Watershed es una técnica de segmentación de imágenes que se utiliza para separar regiones contiguas en una imagen que están separadas por líneas de contorno. La idea principal del algoritmo es imaginar la intensidad de los píxeles de la imagen como una superficie topográfica, donde los mínimos locales corresponden a los valles y las cuencas de agua representan las regiones que deseamos segmentar. Inicialmente, se marcan los mínimos locales como puntos de inicio de inundación, luego se simula un proceso de inundación desde estos puntos, donde se llenan las cuencas de agua y se encuentran los límites naturales entre las regiones.\n",
    "\n",
    "De esta manera, el algoritmo Watershed divide la imagen en regiones significativas, creando una segmentación que refleja los cambios abruptos en la intensidad de los píxeles. Sin embargo, este método puede producir una sobresegmentación, donde se generan regiones demasiado pequeñas y numerosas, lo que requiere pasos adicionales, como la imposición de mínimos locales, para obtener una segmentación más precisa y útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "% Leer la imagen \n",
    "imagen = imread('higado.bmp');\n",
    "\n",
    "% Imagen en escala de grises\n",
    "imagen_gris = rgb2gray(imagen);\n",
    "\n",
    "% Paso 1: Calcular la imagen de gradiente\n",
    "mascara = fspecial('sobel'); % Crear la mascara de Sobel\n",
    "gradiente_x = imfilter(imagen_gris, mascara'); % Calcular el gradiente en dirección x\n",
    "gradiente_y = imfilter(imagen_gris, mascara); % Calcular el gradiente en dirección y\n",
    "gradiente = sqrt(double(gradiente_x).^2 + double(gradiente_y).^2); % Calcular el modulo de los gradientes\n",
    "\n",
    "% Paso 2: Aplicar Watershed a la imagen de gradiente\n",
    "transformada_distancia = bwdist(~imbinarize(gradiente)); % Transformada de distancia\n",
    "transformada_distancia = -transformada_distancia;\n",
    "transformada_distancia(~imbinarize(gradiente)) = -Inf; % Establecer los minimos locales\n",
    "segmentacion = watershed(transformada_distancia); % Aplicar Watershed\n",
    "segmentacion(~mascara) = 0;\n",
    "\n",
    "% Paso 3: Utilizar imimposemin para imponer mínimos en las zonas adecuadas\n",
    "% Operaciones de morfologia matematica para limpiar la imagen y mejorar la segmentacion\n",
    "I = imagen_gris;\n",
    "se = strel(\"disk\",20);\n",
    "Io = imopen(I,se);\n",
    "Ie = imerode(I,se);\n",
    "Iobr = imreconstruct(Ie,I);\n",
    "Ioc = imclose(Io,se);\n",
    "Iobrd = imdilate(Iobr,se);\n",
    "Iobrcbr = imreconstruct(imcomplement(Iobrd),imcomplement(Iobr));\n",
    "Iobrcbr = imcomplement(Iobrcbr);\n",
    "\n",
    "% Identificar maximos regionales\n",
    "fgm = imregionalmax(Iobrcbr);\n",
    "se2 = strel(ones(5,5));\n",
    "fgm2 = imclose(fgm,se2);\n",
    "fgm3 = imerode(fgm2,se2);\n",
    "fgm4 = bwareaopen(fgm3,20);\n",
    "\n",
    "% Binarizar la imagen de fondo\n",
    "bw = imbinarize(Iobrcbr);\n",
    "D = bwdist(bw);\n",
    "DL = watershed(D);\n",
    "bgm = DL == 0;\n",
    "\n",
    "% Imponer minimos locales en las regiones adecuadas\n",
    "minimos = imimposemin(gradiente, bgm | fgm4);\n",
    "\n",
    "% Paso 4: Obtener el resultado de Watershed sobre la imagen modificada\n",
    "segmentacion_final = watershed(minimos);\n",
    "\n",
    "% Visualizacion de los resultados\n",
    "figure;\n",
    "subplot(2,2,1); imshow(imagen); title('Imagen Original');\n",
    "subplot(2,2,2); imshow(gradiente); title('Imagen de Gradiente');\n",
    "subplot(2,2,3); imshow(label2rgb(segmentacion,'jet',[.5 .5 .5])); title('Resultado Watershed');\n",
    "subplot(2,2,4); imshow(label2rgb(segmentacion_final)); title('Resultado con mínimos impuestos');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "\n",
    "Como se puede observar, al aplicar Watershed directamente sobre la magnitud del gradiente se produce una sobresegamentación. En cambio, al imponer mínimos locales se obtiene un resultado mejorado, diferenciando las diferentes zonas de la imagen. Aun así, el resultado sigue sin ser muy preciso, lo que sugiere que pueden ser necesarios más ajustes o técnicas adicionales para obtener una segmentación más adecuada.\n",
    "\n",
    "<img src=\"result_ejer_C.png\" alt=\"Descripción de la imagen\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio D) Segmentación usando el modelo de Chan_Vese\n",
    "\n",
    "El modelo de segmentación Chan-Vese es un modelo deformable que divide la imagen en dos regiones con máxima diferencia en media de gris. Este modelo evoluciona una superficie en función de las energías medidas, en concreto la diferencia de puntos de dentro y fuera de la región segmentada, junto con una energía medida de la curvatura de la superficie.\n",
    "\n",
    "Para comenzar, se han analizada y modificado los parámetros del algoritmo proporcionados en los archivos `chanvese.m` y `chanvese_demo.m`; aumentando el valor de la máscara inicial para lograr una mejora en la segmentación de la imagen.\n",
    "\n",
    "Después, se ha incluido un criterio de parada en la función de los puntos analizados en el presente y el pasado, en comparación con un umbral establecido, con el propósito de determinar si la segmentación se ha estabilizado y si los pasos siguientes pueden generar sobresegmentación\n",
    "\n",
    "Por último, se ha limitado el tamaño máximo de la región segmentada para controlar dicha región segmentada y evitar que abarque zonas no deseadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio E) Segmentación usando atlas\n",
    "\n",
    "En este apartado, abordaremos la segmentación de imágenes médicas utilizando un enfoque basado en atlas. Nos centraremos en cómo segmentar una imagen utilizando otra imagen ya etiquetada como referencia. La tarea consiste en desarrollar un código que segmente la imagen MR mediante la asignación de etiquetas basadas en la similitud entre parches de las imágenes. En el contexto de imágenes del cerebro, se buscarán parches en una vecindad de 11x11x11 alrededor de cada punto de interés, utilizando un kernel de 3x3x3 para evaluar la similitud.\n",
    "\n",
    "El algoritmo es muy lento, y para evaluar regiones suficientemente grandes no es viable, por lo que se ha escogido una ROI dentro del volumen tridimensional sobre el aplicamos la segmentación.\n",
    "\n",
    "El algoritmo toma un punto a clasificar, y en una vecindad de 11x11x11 en el mismo punto en la imagen del atlas, busca la mayor similitud en kernels de 3x3x3. Esta similitud se realiza usando la diferencia media en dichos kernels con respecto al punto original. El punto que tenga la menor diferencia será el que de la etiqueta para clasificar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Leer las imágenes\n",
    "mr_image = sitk.ReadImage(\"MaterialP2/MR.nii\")\n",
    "ft1_image = sitk.ReadImage(\"MaterialP2/fT1.nii\")\n",
    "flabels_image = sitk.ReadImage(\"MaterialP2/fLabels.nii\")\n",
    "\n",
    "# Convertir las imágenes a arrays numpy\n",
    "mr_array = sitk.GetArrayFromImage(mr_image)\n",
    "#print(mr_array.shape)\n",
    "ft1_array = sitk.GetArrayFromImage(ft1_image)\n",
    "flabels_array = sitk.GetArrayFromImage(flabels_image)\n",
    "\n",
    "# Crear un subplot con 1 fila y 3 columnas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Las imágenes volumétricas\n",
    "images = [mr_array, ft1_array, flabels_array]\n",
    "titles = ['MR', 'fT1', 'fLabels']\n",
    "index = 15\n",
    "# Mostrar las primeras tres imágenes en un solo plot\n",
    "for i in range(3):\n",
    "    axes[i].imshow(images[i][index, :, :], cmap='gray')  # Seleccionar la imagen correspondiente al elemento 15\n",
    "    axes[i].set_title(titles[i])\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Definir las coordenadas de la ROI en mr_array (ejemplo)\n",
    "x_start_roi, y_start_roi, z_start_roi = 20, 50, 50\n",
    "x_end_roi, y_end_roi, z_end_roi = 30, 150, 150\n",
    "\n",
    "# Crear una matriz vacía para almacenar los resultados en la ROI\n",
    "resultados_roi = np.empty((x_end_roi - x_start_roi, y_end_roi - y_start_roi, z_end_roi - z_start_roi))\n",
    "\n",
    "# Iterar sobre cada voxel dentro de la ROI\n",
    "for x in range(x_start_roi, x_end_roi):\n",
    "    for y in range(y_start_roi, y_end_roi):\n",
    "        for z in range(z_start_roi, z_end_roi):\n",
    "            # Coordenadas del voxel de referencia en la imagen derecha\n",
    "            x_ref, y_ref, z_ref = x, y, z\n",
    "            \n",
    "            # Definir las coordenadas de la región 11x11x11 en la imagen derecha\n",
    "            x_start = max(x_ref - 5, x_start_roi)\n",
    "            x_end = min(x_ref + 6, x_end_roi)\n",
    "            y_start = max(y_ref - 5, y_start_roi)\n",
    "            y_end = min(y_ref + 6, y_end_roi)\n",
    "            z_start = max(z_ref - 5, z_start_roi)\n",
    "            z_end = min(z_ref + 6, z_end_roi)\n",
    "\n",
    "            # Inicializar el voxel más similar y su diferencia mínima\n",
    "            voxel_mas_similar = None\n",
    "            diferencia_minima = float('inf')\n",
    "\n",
    "            # Iterar sobre la región 11x11x11 en la imagen derecha\n",
    "            for xi in range(x_start, x_end):\n",
    "                for yi in range(y_start, y_end):\n",
    "                    for zi in range(z_start, z_end):\n",
    "                        # Definir las coordenadas del kernel 3x3x3 alrededor del voxel de referencia\n",
    "                        x_kernel_start = max(xi - 1, x_start)\n",
    "                        x_kernel_end = min(xi + 2, x_end)\n",
    "                        y_kernel_start = max(yi - 1, y_start)\n",
    "                        y_kernel_end = min(yi + 2, y_end)\n",
    "                        z_kernel_start = max(zi - 1, z_start)\n",
    "                        z_kernel_end = min(zi + 2, z_end)\n",
    "\n",
    "                        # Calcular la diferencia media en el kernel 3x3x3\n",
    "                        diferencia_media = np.mean(np.abs(mr_array[x:x+1, y:y+1, z:z+1] - mr_array[x_kernel_start:x_kernel_end, y_kernel_start:y_kernel_end, z_kernel_start:z_kernel_end]))\n",
    "                        \n",
    "                        # Actualizar el voxel más similar si encontramos una diferencia mínima\n",
    "                        if diferencia_media < diferencia_minima:\n",
    "                            diferencia_minima = diferencia_media\n",
    "                            voxel_mas_similar = flabels_array[xi, yi, zi]  # Voxel más similar encontrado\n",
    "\n",
    "            # Almacenar el voxel más similar en los resultados\n",
    "            resultados_roi[x - x_start_roi, y - y_start_roi, z - z_start_roi] = voxel_mas_similar\n",
    "\n",
    "\n",
    "\n",
    "# Elementos a mostrar\n",
    "elementos_a_mostrar = [0, 5, 9]\n",
    "\n",
    "# Mostrar los elementos seleccionados\n",
    "for idx, elemento in enumerate(elementos_a_mostrar, 1):\n",
    "    plt.subplot(1, len(elementos_a_mostrar), idx)\n",
    "    plt.imshow(resultados_roi[elemento, :, :], cmap='gray')  # Seleccionar el plano específico\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Elemento {elemento}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "\n",
    "Imagen en la ROI `[20:30],[50,150],[50,150]`, se muestran las slices 0,5,9 que se corresponden con las slices 20,25,29 de la imagen original\n",
    "\n",
    "<img src=\"ejerE.png\" alt=\"Descripción de la imagen\" width=\"700\"/>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
